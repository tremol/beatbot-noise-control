{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we build on the model training of Exploration 2 in the real-time listening and processing of Exploration 3, to build a single unified workflow. Running this allows you to, in this one self-contained notebook,\n",
    "* specify the noises you want your model to recognize\n",
    "* record training and testing data for those noises\n",
    "* train a model on the data, and evaluate its performance\n",
    "* use the model with a listener to recognize noises in real-time and act on them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Exploration 3, we will use sounddevice to listen and record audio. This outputs numpy arrays. We will use this to construct training and testing datasets, which will pass mel spectrograms on to the network. Once trained, this network will be used to recognize noises, again by converting incoming audio into spectrograms and generating predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time listening: general functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to continuously listen for noises, and pass them to a processing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import queue\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 Built-in Microphone, Core Audio (2 in, 0 out)\n",
      "< 1 Built-in Output, Core Audio (0 in, 2 out)\n",
      "> 2 SpeechMatic USB MultiAdapter, Core Audio (1 in, 2 out)\n"
     ]
    }
   ],
   "source": [
    "########### PARAMETERS ###########\n",
    "\n",
    "device = 2 # select the microphone. Use sd.query_devices() to see options\n",
    "print(sd.query_devices())\n",
    "\n",
    "BATCH_DURATION = 0.02      # listen for noises BATCH_DURATION (seconds) at a time\n",
    "THRESHOLD_MULTIPLIER = 5   # detect a spike when the next batch is at least THRESHOLD_MULTIPLIER times bigger\n",
    "THRESHOLD_ABSOLUTE = 0.005 # ignore any spikes that don't rise above this. Too many false positives without this\n",
    "BATCHES_PER_NOISE = 3      # collect BATCHES_PER_NOISE batches of audio input per detected noise\n",
    "\n",
    "samplerate = sd.query_devices(device, 'input')['default_samplerate']\n",
    "# optional for future: set the FFT window size based on the sample rate\n",
    "\n",
    "blocksize = int(samplerate * BATCH_DURATION) # get the block (batch) size in frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Functions for continuous listening and processing ###########\n",
    "\n",
    "# bundling these is easier than declaring them 'global' in the below\n",
    "class listen:\n",
    "    \"\"\" Helper variables for processing continuous audio input \"\"\"\n",
    "    \n",
    "    def reset():\n",
    "        listen.prev_max = 1.\n",
    "        listen.batches_to_collect = 0\n",
    "        listen.batches_collected = 0\n",
    "        listen.current_noise = None\n",
    "        listen.start = time.time()\n",
    "\n",
    "        listen.processing_start = 0 # for timing the total processing time\n",
    "        listen.processing_end = 0\n",
    "\n",
    "        listen.q_batches = queue.Queue() # a FIFO queue\n",
    "        listen.all_audio = []  # could use this to collect all audio (uncomment line in callback)\n",
    "        listen.all_noises = [] # could use this to collect all noises. Use the processing_function to append\n",
    "    \n",
    "def callback(indata, frames, time_pa, status):\n",
    "    \"\"\" Detect if a noise has been made, and add audio to the queue. \"\"\"\n",
    "    if status:\n",
    "        print('STATUS: ', str(status))\n",
    "    if any(indata):\n",
    "        indata_copy = indata.copy()\n",
    "        new_max = np.absolute(indata_copy).max()\n",
    "        # listen.all_audio.append(indata_copy)\n",
    "        \n",
    "        # Gather audio data if more is required. Make sure to *copy* the input data.\n",
    "        if listen.batches_to_collect > 0:\n",
    "            listen.q_batches.put_nowait(indata_copy)\n",
    "            listen.batches_collected  += 1\n",
    "            listen.batches_to_collect -= 1\n",
    "                \n",
    "        # Otherwise, see if a new noise has been detected\n",
    "        elif ( new_max > THRESHOLD_ABSOLUTE and\n",
    "               new_max > THRESHOLD_MULTIPLIER * listen.prev_max ):\n",
    "            \n",
    "            listen.processing_start = time.time()\n",
    "            \n",
    "            listen.q_batches.put_nowait(indata_copy)\n",
    "            listen.batches_collected += 1\n",
    "            listen.batches_to_collect = BATCHES_PER_NOISE - 1 # get more batches\n",
    "               \n",
    "        listen.prev_max = new_max\n",
    "        \n",
    "    else:\n",
    "        print('no input')\n",
    "\n",
    "def time_elapsed(duration):\n",
    "    def _time_elapsed():\n",
    "        return time.time() - listen.start > duration\n",
    "    return _time_elapsed\n",
    "\n",
    "def print_processing_time():\n",
    "    listen.processing_end = time.time()\n",
    "    print('Processing took {:.4f} sec\\n'.format(\n",
    "        listen.processing_end - listen.processing_start))\n",
    "        \n",
    "def listen_and_process(processing_function, stop_condition=time_elapsed(3),\n",
    "                       device=device, print_after_processing=None):\n",
    "    \"\"\" Listen continuously for noises until stop_condition() returns True (default: wait 3 sec).\n",
    "    As each noises heard, process is using processing_function. Return all noises at the end. \"\"\"\n",
    "\n",
    "    listen.reset() # reinitialize helper variables\n",
    "    \n",
    "    with sd.InputStream(device=device, channels=1, callback=callback,\n",
    "                        blocksize=blocksize,\n",
    "                        samplerate=samplerate):\n",
    "        print('Listening...')\n",
    "        while True:\n",
    "            \n",
    "            # data collects if it meets the threshold. Process when enough data is in queue:\n",
    "            if listen.batches_collected >= BATCHES_PER_NOISE:\n",
    "                data = []\n",
    "                for _ in range(BATCHES_PER_NOISE):\n",
    "                    data.append( listen.q_batches.get_nowait() )\n",
    "                listen.batches_collected -= BATCHES_PER_NOISE\n",
    "                \n",
    "                listen.current_noise = np.concatenate( data, axis=None )\n",
    "                \n",
    "                processing_function( listen.current_noise )\n",
    "                \n",
    "                # print something after processing, if desired\n",
    "                print_after_processing() if print_after_processing else None\n",
    "                    \n",
    "            # listen until the condition is met\n",
    "            if stop_condition():\n",
    "                break\n",
    "        print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording audio data for training/testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the above functions to make a listener to record training and testing data for our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## A listener to record training/testing data. ##########\n",
    "\n",
    "# a helper function to get nonnegative integer input\n",
    "def get_int_input():\n",
    "    while True:\n",
    "        response = input() # response is a string\n",
    "        try:\n",
    "            val = int(response)\n",
    "            if val >= 0:\n",
    "                break\n",
    "            print('Integer must be non-negative.')\n",
    "        except:\n",
    "            print('Please enter an integer.')\n",
    "        \n",
    "    return val\n",
    "\n",
    "def record_model_data(device=device):\n",
    "    \"\"\" Prompts the user to label and record noise samples. Returns a dictionary with labels as keys\n",
    "    and lists of flattened numpy arrays (one array per noise sample) as values. \"\"\"\n",
    "    \n",
    "    noise_data_dict = {}\n",
    "    noise_count = 0\n",
    "    \n",
    "    def gather_and_progress(label, total):\n",
    "        def _gather_and_progress(rec):\n",
    "            nonlocal noise_count\n",
    "            \n",
    "            listen.all_noises.append( rec )\n",
    "            noise_count += 1\n",
    "            print(noise_count, end=', ')\n",
    "\n",
    "        return _gather_and_progress\n",
    "      \n",
    "    same_num_for_each = False\n",
    "    print('Would you like to record the same number of samples for each noise type? (enter y for yes)')\n",
    "    answer = input()\n",
    "    if 'y' in answer:\n",
    "        same_num_for_each = True\n",
    "        print('How many noise samples would you like to record for each?')\n",
    "        num = get_int_input()\n",
    "    else:\n",
    "        print('We recommend recording similar numbers for each type, to avoid biasing the model.\\n')\n",
    "    \n",
    "    while True:    \n",
    "        print('Noises recorded so far:', list(noise_data_dict.keys()))\n",
    "        print('Enter text label for next noise (leave blank to exit):')\n",
    "        label = input()\n",
    "        if not label:\n",
    "            return noise_data_dict\n",
    "        if label in noise_data_dict:\n",
    "            print('You have already recorded {} samples of this noise. You may now record more.'.format(\n",
    "                    len(noise_data_dict[label]))\n",
    "                 )\n",
    "        if not same_num_for_each:\n",
    "            print('How many noise samples would you like to record?')\n",
    "            num = get_int_input()\n",
    "            if num == 0:\n",
    "                continue\n",
    "        \n",
    "        clear_output() # clear jupyter output\n",
    "        print('Noises recorded so far:', list(noise_data_dict.keys()))\n",
    "        print('Please start recording.\\n')\n",
    "        print('\"{}\" noises recorded (out of {}): '.format(label, num))\n",
    "        noise_count = 0\n",
    "        listen_and_process(processing_function=gather_and_progress(label, num), \n",
    "                           stop_condition=lambda: noise_count >= num,\n",
    "                           device=device,\n",
    "                           print_after_processing=None)\n",
    "        print('')\n",
    "\n",
    "        # save the list of recorded noises\n",
    "        if label in noise_data_dict:\n",
    "            noise_data_dict[label] += listen.all_noises.copy()\n",
    "        else:\n",
    "            noise_data_dict[label] = listen.all_noises.copy()\n",
    "        \n",
    "    return noise_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# my_recordings = record_model_data()\n",
    "# print(my_recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio processing: preparing spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to create a spectrogram from a noise sample recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio.transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### PARAMETERS ###########\n",
    "N_MELS = 28                # the number of mel filterbanks in each spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spectrogram(noise_sample, samplerate=samplerate, n_mels=N_MELS):\n",
    "    \"\"\" Takes a noise_sample as a flattened numpy.array,\n",
    "    and returns a mel spectrogram as a 2D torch.tensor \"\"\"\n",
    "    \n",
    "    # normalize to have unit mean, and compute the spectrogram\n",
    "    normed_sample = torch.from_numpy(noise_sample) / noise_sample.mean()\n",
    "    mel = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=samplerate, n_mels=n_mels)(normed_sample)\n",
    "    \n",
    "    return mel.log2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# my_spectrogram = generate_spectrogram( noise_sample=my_recordings['t'][0] )\n",
    "# plt.figure(figsize=(2, 2))\n",
    "# plt.imshow(my_spectrogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural net: preparing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a dictionary of labeled noise sample recordings, prepare the datasets and data loaders needed to train and test the model. Some of the model construction, training, and evaluation code here has been adapted from a [pytorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the noise data for handing to the convolutional neural network, for training and testing\n",
    "\n",
    "class NoisesDataset(Dataset):\n",
    "    \"\"\" Noises dataset. Takes a dictionary of recordings and returns spectrograms when data is requested. \n",
    "    A channel dimension is added to each spectrogram, as needed for the CNN. \"\"\"\n",
    "\n",
    "    def __init__(self, noise_data_dict, samplerate=samplerate, n_mels=N_MELS): \n",
    "        \"\"\" Initialization: \n",
    "        Takes a dictionary of noise samples, with labels as keys and lists of\n",
    "        flattened numpy arrays (one array per noise sample) as values. \n",
    "        Computes spectrograms for each. \"\"\"\n",
    "        self.noise_data_dict = noise_data_dict\n",
    "        self.noise_samples = []\n",
    "        self.labels = []\n",
    "        \n",
    "        self.noise_str_to_int = {} # correspondences between integer and string labels\n",
    "        self.noise_int_to_str = {} \n",
    "        i = 0\n",
    "        \n",
    "        for label, list_of_arrays in noise_data_dict.items():\n",
    "            # extract samples and labels from the dictionary\n",
    "            num_samples = len(noise_data_dict[label])\n",
    "            self.noise_samples += noise_data_dict[label]\n",
    "            self.labels += [label] * num_samples\n",
    "            \n",
    "            # assign a unique integer to each string label\n",
    "            if label not in self.noise_str_to_int:\n",
    "                self.noise_str_to_int[label] = i\n",
    "                self.noise_int_to_str[i] = label\n",
    "                i += 1\n",
    "        \n",
    "        # compute spectrograms, and convert labels to integers\n",
    "        self.spectrograms = [ generate_spectrogram(s, samplerate, n_mels) \n",
    "                              for s in self.noise_samples ]\n",
    "        self.labels = [ self.noise_str_to_int[ L ] for L in self.labels ]\n",
    "\n",
    "    def __len__(self):\n",
    "        \" Return  the total number of samples \"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, sample_index):\n",
    "        \" Return one sample of data \"\n",
    "        # Load data and get (integer) label\n",
    "        # Note the CNN will expect the first tensor dimension to be the channel, hence the unsqueeze\n",
    "        X = self.spectrograms[sample_index].unsqueeze(0)\n",
    "        y = self.labels[sample_index]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "# adapted from https://stackoverflow.com/questions/53916594/typeerror-object-of-type-numpy-int64-has-no-len\n",
    "def prepare_data_loaders(full_dataset, training_fraction=0.8, batch_size=8):\n",
    "    \"\"\" Prepare data loaders for training and testing of the model. \"\"\"\n",
    "\n",
    "    train_size = int(training_fraction * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "    train_params = {\n",
    "        'batch_size': batch_size,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 1,\n",
    "    }\n",
    "    train_loader = DataLoader(dataset=train_dataset, **train_params)\n",
    "    test_loader  = DataLoader(dataset=test_dataset)\n",
    "    \n",
    "    return train_loader, test_loader, train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# my_dataset = NoisesDataset(my_recordings)\n",
    "# my_train_loader, my_test_loader, my_train_dataset, my_test_dataset = prepare_data_loaders(my_dataset, batch_size=8)\n",
    "\n",
    "# # get some random training spectrograms\n",
    "# my_train_dataiter = iter(my_train_loader)\n",
    "# my_spectrograms, my_labels = my_train_dataiter.next()\n",
    "# my_batch_size = 8\n",
    "\n",
    "# # show spectrograms and print labels\n",
    "# fig, ax = plt.subplots(1, my_batch_size)\n",
    "# for i in range(len(my_spectrograms)):\n",
    "#     ax[i].imshow(my_spectrograms[i][0].numpy()) # the 0 selects the first (only) channel\n",
    "# print(' '.join('{:>4s}'.format(my_dataset.noise_int_to_str[my_labels[j].item()]) for j in range(my_batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural net: defining and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the convolutional neural network, and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, image_size, noise_int_to_str):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.image_size = image_size\n",
    "        self.noise_int_to_str = noise_int_to_str\n",
    "        \n",
    "        # image_size is a 2-tuple, the expected dimensions of each spectrogram\n",
    "        # .... or a 3-tuple, if the channel has already been added\n",
    "        if   len(image_size) == 2:\n",
    "            h, w = image_size\n",
    "        elif len(image_size) == 3:\n",
    "            channel, h, w = image_size\n",
    "        \n",
    "        # number of output nodes, (square) kernel size, and pool size per convolution layer,\n",
    "        # assuming the stride for pooling is the same as the pool size\n",
    "        kernels = [3, 3]\n",
    "        pool = 2\n",
    "        \n",
    "        # compute the number of input nodes for the first dense layer\n",
    "        h_out, w_out = h, w\n",
    "        for k in kernels:\n",
    "            # the convolution.\n",
    "            h_out += -k + 1\n",
    "            w_out += -k + 1\n",
    "            \n",
    "            # the pool. (from help(torch.nn.MaxPool2d))\n",
    "            h_out = int( (h_out - pool) / pool + 1 )\n",
    "            w_out = int( (w_out - pool) / pool + 1 )\n",
    "            \n",
    "        self.image_out = h_out * w_out\n",
    "        \n",
    "        # define the layers. The numbers of nodes chosen do not have deep thought behind them.\n",
    "        self.conv0 = nn.Conv2d(1, 32, kernels[0])\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv1 = nn.Conv2d(32, 10, kernels[1])\n",
    "        self.fc0 = nn.Linear(10 * self.image_out, 50)\n",
    "        self.fc1 = nn.Linear(50, 10)\n",
    "        # number of output nodes for final dense layer: the number of noise types        \n",
    "        self.fc2 = nn.Linear(10, len(noise_int_to_str))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv0(x)))\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 10 * self.image_out)\n",
    "        x = F.relu(self.fc0(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, epochs, train_loader, batch_progress=50):\n",
    "    \"\"\" Use training data from train_loader to train net for a number of epochs,\n",
    "    using a cross entropy loss function and Adam as the optimizer. \"\"\"\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters())\n",
    "    \n",
    "    batch_num = 0\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        \n",
    "        batch_running_loss = 0.0\n",
    "        \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # accrue loss for printing\n",
    "            batch_running_loss += loss.item()\n",
    "            \n",
    "            if batch_num % batch_progress == batch_progress-1:\n",
    "                print('[{:d}, {:5d}] loss: {:.3f}'.format(\n",
    "                  epoch + 1, i + 1, batch_running_loss / batch_progress))\n",
    "                batch_running_loss = 0.0\n",
    "                batch_num = 0\n",
    "            \n",
    "            batch_num += 1\n",
    "        \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# my_net = Net(my_spectrogram.size(), my_dataset.noise_int_to_str)\n",
    "# train_net(my_net, 50, my_train_loader, batch_progress=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the accuracy of the model against the testing and training sets, and compute the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_rating(net, dataloader, dataset_label):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_targets = torch.tensor([], dtype=torch.long)\n",
    "    all_predictions = torch.tensor([], dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            spectrograms, labels = data\n",
    "            outputs = net(spectrograms)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_predictions = torch.cat( \n",
    "                (all_predictions, predicted), dim=0 )\n",
    "            all_targets = torch.cat( \n",
    "                (all_targets, labels), dim=0 )\n",
    "            \n",
    "    print('Accuracy of the network on the {} {} spectrograms: {:.0f} %'.format(\n",
    "        total,\n",
    "        dataset_label,\n",
    "        100 * correct / total))\n",
    "    \n",
    "    return all_predictions, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://deeplizard.com/learn/video/0LhiS6yu2qQ\n",
    "def plot_confusion_matrix(predictions, targets, labels_int_to_str, \n",
    "                          normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \n",
    "    stacked = torch.stack( [targets, predictions], dim=1 )\n",
    "    all_int_labels = sorted(list(labels_int_to_str.keys()))\n",
    "    num_labels = len(all_int_labels)\n",
    "    confusion_matrix = torch.zeros(num_labels, num_labels, dtype=torch.int64)\n",
    "\n",
    "    for pair in stacked:\n",
    "        target_label, prediction_label = pair.tolist()\n",
    "        confusion_matrix[target_label, prediction_label] += 1\n",
    "\n",
    "    classes = [ labels_int_to_str[i] for i in all_int_labels ]    \n",
    "    cm = confusion_matrix # rename for compactness\n",
    "        \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization:')\n",
    "\n",
    "        \n",
    "    size = min(num_labels + 1, 8)\n",
    "    plt.figure(figsize=(size, size))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", \n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# accuracy_rating(my_net, my_train_loader, 'training')\n",
    "# preds, targets = accuracy_rating(my_net, my_test_loader, 'test')\n",
    "\n",
    "# plot_confusion_matrix(preds, targets, my_dataset.noise_int_to_str);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time listening and recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the trained model in hand, make a listener to recognize noises and act on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model, noise_sample, samplerate=samplerate, n_mels=N_MELS):\n",
    "    \"\"\" Build the spectrogram and use our model to recognize the noise \"\"\"\n",
    "    \n",
    "    mel = generate_spectrogram(noise_sample, samplerate, n_mels)\n",
    "\n",
    "    # change from torch.Size([A, B]) to torch.Size([1, 1, A, B])\n",
    "    mel = mel[None, None, :, :]\n",
    "    \n",
    "    # run through the model and get prediction\n",
    "    output = model(mel)\n",
    "    energy, label = torch.max(output.data, 1)\n",
    "    \n",
    "    # return the string label of the noise\n",
    "    return model.noise_int_to_str[label.item()]\n",
    "\n",
    "def print_noise(noise_heard):\n",
    "    \"\"\" Print the string label of the noise that has been heard. \"\"\"\n",
    "    print(noise_heard, end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_recognize_and_respond(model, act_on_noise, device, duration=5):\n",
    "    \"\"\" Continuously listen for noises for duration (sec), then recognize them\n",
    "    with the model and respond with the function act_on_noise. \"\"\"\n",
    "    \n",
    "    def processing_function(noise_sample):\n",
    "        pred = get_prediction(model, noise_sample)\n",
    "        act_on_noise(pred)\n",
    "    \n",
    "    listen_and_process(processing_function=processing_function, \n",
    "                           stop_condition=time_elapsed(duration),\n",
    "                           device=device,\n",
    "                           print_after_processing=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note this supposes that the default samplerate and n_mels for get_prediction are the same as those used for the training dataset. This could be made more robust by allowing processing_function to accept the sample rate as well as a numpy array, and by recording the n_mels used in the dataset the model was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# listen_recognize_and_respond(my_net, print_noise, 2, duration=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From recording to recognizing: all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    40] loss: 0.683\n",
      "[4,    19] loss: 0.096\n",
      "[5,    58] loss: 0.165\n",
      "[7,    37] loss: 0.072\n",
      "[9,    16] loss: 0.024\n",
      "[10,    55] loss: 0.069\n",
      "Finished Training\n",
      "Accuracy of the network on the 120 test spectrograms: 98 %\n",
      "Confusion matrix, without normalization:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my_recordings = record_model_data()\n",
    "\n",
    "my_dataset = NoisesDataset(my_recordings)\n",
    "my_train_loader, my_test_loader, _, _ = prepare_data_loaders(my_dataset, batch_size=8)\n",
    "\n",
    "my_net = Net(my_dataset[0][0].size(), my_dataset.noise_int_to_str)\n",
    "train_net(my_net, 10, my_train_loader, batch_progress=100)\n",
    "\n",
    "preds, targets = accuracy_rating(my_net, my_test_loader, 'test')\n",
    "plot_confusion_matrix(preds, targets, my_dataset.noise_int_to_str);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "click, click, click, tsk, click, tsk, ch, ch, ch, click, tsk, tsk, t, t, t, k, k, k, t, p, p, p, t, k, ch, ch, ch, ch, ch, Done.\n"
     ]
    }
   ],
   "source": [
    "listen_recognize_and_respond(my_net, print_noise, 2, duration=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
