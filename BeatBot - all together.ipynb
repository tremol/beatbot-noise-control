{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we build on the model training of Exploration 2 and the real-time listening and processing of Exploration 3 (see `explorations` folder), to build a single unified workflow. Running this allows you to, in this one self-contained notebook,\n",
    "* specify the noises you want your model to recognize\n",
    "* record training and testing data for those noises\n",
    "* train a model on the data, and evaluate its performance\n",
    "* use the model with a listener to recognize noises in real-time and act on them\n",
    "\n",
    "At present, this can recognize percussive noises, like short clicks or consonant sounds ('t', 'p', ...). Also, it assumes any percussive sound it hears is something to be recognized: it will not reject noises it has not been trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and run a BeatBot here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### These will fail until the rest of the notebook has been run. Scroll down a bit to \"Component Functions\", and then select \"Cell -> Run All Below\" in the Jupyter menu. Then come back to rerun these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First select your microphone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0 # select the microphone. Use sd.query_devices() to see options\n",
    "print(sd.query_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record noise samples and train a model. (~100 samples per noise gives reasonable results.) Save the resulting audio data and model, if you wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model, my_recordings = build_beatbot(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out your new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will run for 10 sec, printing out any noise it hears during that time.\n",
    "run_beatbot(my_model, print_noise, device=device, duration=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already have audio data or a model saved, you can load them with ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_recordings = load_noise_sample_dict(filename='my_noise_data.npy')\n",
    "# my_model = load_model(filename='my_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also build on an old set of recordings with ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_new_model, my_new_recordings = build_beatbot(device=device, starting_noise_data=my_recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or skip recording entirely (and testing, if you want) with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_new_model, my_new_recordings = build_beatbot(device=device, starting_noise_data=my_recordings,\n",
    "#                                                 skip_recording=True, skip_testing_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyboard control: up down left right escape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to play a videogame, like Crypt of the Necrodancer, with this noise control. Let's introduce some basic keyboard control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic keyboard control\n",
    "\n",
    "def press_key(noise_heard):\n",
    "    keyboard_mapping = {\n",
    "        't': 'up',\n",
    "        'k': 'right',\n",
    "        'p': 'down',\n",
    "        'tsk': 'left',\n",
    "        'cluck': 'escape',\n",
    "    }\n",
    "    try:\n",
    "        pyautogui.press( keyboard_mapping[noise_heard] )\n",
    "    except:\n",
    "        print('No keyboard mapping for \"{}\"'.format(noise_heard))\n",
    "    print_noise( noise_heard )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And define a model that only recognizes these five noises, even if we recorded more earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_recordings_subset = { k: v for k, v in my_recordings.items() if k in ('t', 'k', 'p', 'tsk', 'cluck') }\n",
    "necrodancer_model, _ = build_beatbot(device=device, skip_recording=True, starting_noise_data=my_recordings_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make it run for 20 min, switch over to the game, and play!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_beatbot(necrodancer_model, press_key, device=device, duration=20*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Component functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of this notebook is all of the pieces that go into making the above work. Most of this was developed in the Exploration notebooks, and adapted here into a more cohesive whole. You may wish to check out those notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time listening: general functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to continuously listen for noises, and pass them to a processing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import queue\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### PARAMETERS ###########\n",
    "\n",
    "device = 0 # select the microphone. Use sd.query_devices() to see options\n",
    "print(sd.query_devices())\n",
    "\n",
    "BATCH_DURATION = 0.02      # listen for noises BATCH_DURATION (seconds) at a time\n",
    "THRESHOLD_MULTIPLIER = 5   # detect a spike when the next batch is at least THRESHOLD_MULTIPLIER times bigger\n",
    "THRESHOLD_ABSOLUTE = 0.005 # ignore any spikes that don't rise above this. Too many false positives without this\n",
    "BATCHES_PER_NOISE = 3      # collect BATCHES_PER_NOISE batches of audio input per detected noise\n",
    "\n",
    "samplerate = sd.query_devices(device, 'input')['default_samplerate']\n",
    "# optional for future: set the FFT window size based on the sample rate\n",
    "\n",
    "blocksize = int(samplerate * BATCH_DURATION) # get the block (batch) size in frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Functions for continuous listening and processing ###########\n",
    "\n",
    "# bundling these is easier than declaring them 'global' in the below\n",
    "class listen:\n",
    "    \"\"\" Helper variables for processing continuous audio input \"\"\"\n",
    "    \n",
    "    def reset():\n",
    "        listen.prev_max = 1.\n",
    "        listen.batches_to_collect = 0\n",
    "        listen.batches_collected = 0\n",
    "        listen.current_noise = None\n",
    "        listen.start = time.time()\n",
    "\n",
    "        listen.processing_start = 0 # for timing the total processing time\n",
    "        listen.processing_end = 0\n",
    "\n",
    "        listen.q_batches = queue.Queue() # a FIFO queue\n",
    "        listen.all_audio = []  # could use this to collect all audio (uncomment line in callback)\n",
    "        listen.all_noises = [] # could use this to collect all noises. Use the processing_function to append\n",
    "    \n",
    "# The callback function for the sounddevice input stream\n",
    "def callback(indata, frames, time_pa, status):\n",
    "    \"\"\" Detect if a noise has been made, and add audio to the queue. \"\"\"\n",
    "    if status:\n",
    "        print('STATUS: ', str(status))\n",
    "    if any(indata):\n",
    "        indata_copy = indata.copy()\n",
    "        new_max = np.absolute(indata_copy).max()\n",
    "        # listen.all_audio.append(indata_copy)\n",
    "        \n",
    "        # Gather audio data if more is required. Make sure to *copy* the input data.\n",
    "        if listen.batches_to_collect > 0:\n",
    "            listen.q_batches.put_nowait(indata_copy)\n",
    "            listen.batches_collected  += 1\n",
    "            listen.batches_to_collect -= 1\n",
    "                \n",
    "        # Otherwise, see if a new noise has been detected\n",
    "        elif ( new_max > THRESHOLD_ABSOLUTE and\n",
    "               new_max > THRESHOLD_MULTIPLIER * listen.prev_max ):\n",
    "            \n",
    "            listen.processing_start = time.time()\n",
    "            \n",
    "            listen.q_batches.put_nowait(indata_copy)\n",
    "            listen.batches_collected += 1\n",
    "            listen.batches_to_collect = BATCHES_PER_NOISE - 1 # get more batches\n",
    "               \n",
    "        listen.prev_max = new_max\n",
    "        \n",
    "    else:\n",
    "        print('no input')\n",
    "\n",
    "# Returns True if enough time has elapsed\n",
    "def time_elapsed(duration):\n",
    "    def _time_elapsed():\n",
    "        return time.time() - listen.start > duration\n",
    "    return _time_elapsed\n",
    "\n",
    "# A helper to print the time it took to process a single noise recognition\n",
    "def print_processing_time():\n",
    "    listen.processing_end = time.time()\n",
    "    print('Processing took {:.4f} sec\\n'.format(\n",
    "        listen.processing_end - listen.processing_start))\n",
    "\n",
    "# The main generic real-time listening function\n",
    "def listen_and_process(processing_function, stop_condition=time_elapsed(3),\n",
    "                       device=device, print_after_processing=None):\n",
    "    \"\"\" Listen continuously for noises until stop_condition() returns True (default: wait 3 sec).\n",
    "    As each noises heard, process is using processing_function. Return all noises at the end. \"\"\"\n",
    "\n",
    "    listen.reset() # reinitialize helper variables\n",
    "    \n",
    "    with sd.InputStream(device=device, channels=1, callback=callback,\n",
    "                        blocksize=blocksize,\n",
    "                        samplerate=samplerate):\n",
    "        print('Listening...')\n",
    "        while True:\n",
    "            \n",
    "            # data collects if it meets the threshold. Process when enough data is in queue:\n",
    "            if listen.batches_collected >= BATCHES_PER_NOISE:\n",
    "                data = []\n",
    "                for _ in range(BATCHES_PER_NOISE):\n",
    "                    data.append( listen.q_batches.get_nowait() )\n",
    "                listen.batches_collected -= BATCHES_PER_NOISE\n",
    "                \n",
    "                listen.current_noise = np.concatenate( data, axis=None )\n",
    "                \n",
    "                processing_function( listen.current_noise )\n",
    "                \n",
    "                # print something after processing, if desired\n",
    "                print_after_processing() if print_after_processing else None\n",
    "                    \n",
    "            # listen until the condition is met\n",
    "            if stop_condition():\n",
    "                break\n",
    "        print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording audio data for training/testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the above functions to make a listener to record training and testing data for our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## A listener to record training/testing data. ##########\n",
    "\n",
    "# a helper function to get nonnegative integer input\n",
    "def get_int_input():\n",
    "    while True:\n",
    "        response = input() # response is a string\n",
    "        try:\n",
    "            val = int(response)\n",
    "            if val >= 0:\n",
    "                break\n",
    "            print('Integer must be non-negative.')\n",
    "        except:\n",
    "            print('Please enter an integer.')\n",
    "        \n",
    "    return val\n",
    "\n",
    "# Use the generic listening function and add a user interface to record audio data for model training\n",
    "def record_model_data(device=device, starting_noise_data={}):\n",
    "    \"\"\" Prompts the user to label and record noise samples. Returns a dictionary with labels as keys\n",
    "    and lists of flattened numpy arrays (one array per noise sample) as values. \"\"\"\n",
    "    \n",
    "    noise_data_dict = starting_noise_data.copy()\n",
    "    noise_count = 0\n",
    "    \n",
    "    # a helper to gather audio samples and increment the progress counter\n",
    "    def gather_and_progress(label, total):\n",
    "        def _gather_and_progress(rec):\n",
    "            nonlocal noise_count\n",
    "            \n",
    "            listen.all_noises.append( rec )\n",
    "            noise_count += 1\n",
    "            print(noise_count, end=', ')\n",
    "\n",
    "        return _gather_and_progress\n",
    "    \n",
    "    # Ask user how many samples to record\n",
    "    same_num_for_each = False\n",
    "    print('Would you like to record the same number of samples for each noise type? (enter y for yes)')\n",
    "    answer = input()\n",
    "    if 'y' in answer:\n",
    "        same_num_for_each = True\n",
    "        print('How many noise samples would you like to record for each?')\n",
    "        num = get_int_input()\n",
    "    else:\n",
    "        print('We recommend recording similar numbers for each type, to avoid biasing the model.\\n')\n",
    "    \n",
    "    # a helper to print the overall recording progress\n",
    "    def print_progress(noise_data_dict):\n",
    "        print('Noises recorded so far:', { k: len(v) for k, v in noise_data_dict.items() })\n",
    "    \n",
    "    # ask user for noise labels, and listen and record the desired number of samples\n",
    "    while True:    \n",
    "        print_progress(noise_data_dict)\n",
    "        print('Enter text label for next noise (leave blank to exit):')\n",
    "        label = input()\n",
    "        if not label:\n",
    "            return noise_data_dict\n",
    "        if label in noise_data_dict:\n",
    "            print('You have already recorded {} samples of this noise. You may now record more.'.format(\n",
    "                    len(noise_data_dict[label]))\n",
    "                 )\n",
    "        if not same_num_for_each:\n",
    "            print('How many noise samples would you like to record?')\n",
    "            num = get_int_input()\n",
    "            if num == 0:\n",
    "                continue\n",
    "        \n",
    "        clear_output() # clear jupyter output\n",
    "        print_progress(noise_data_dict)\n",
    "        print('Please start recording.\\n')\n",
    "        print('\"{}\" noises recorded (out of {}): '.format(label, num))\n",
    "        noise_count = 0\n",
    "        listen_and_process(processing_function=gather_and_progress(label, num), \n",
    "                           stop_condition=lambda: noise_count >= num,\n",
    "                           device=device,\n",
    "                           print_after_processing=None)\n",
    "        print('')\n",
    "\n",
    "        # save the list of recorded noises\n",
    "        if label in noise_data_dict:\n",
    "            noise_data_dict[label] += listen.all_noises.copy()\n",
    "        else:\n",
    "            noise_data_dict[label] = listen.all_noises.copy()\n",
    "        \n",
    "    return noise_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# my_recordings = record_model_data(device=0)\n",
    "# print(my_recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio processing: preparing spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to create a spectrogram from a noise sample recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio.transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### PARAMETERS ###########\n",
    "N_MELS = 28                # the number of mel filterbanks in each spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spectrogram(noise_sample, samplerate=samplerate, n_mels=N_MELS):\n",
    "    \"\"\" Takes a noise_sample as a flattened numpy.array,\n",
    "    and returns a mel spectrogram as a 2D torch.tensor \"\"\"\n",
    "    \n",
    "    # normalize to have unit mean, and compute the spectrogram\n",
    "    normed_sample = torch.from_numpy(noise_sample) / noise_sample.mean()\n",
    "    mel = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=samplerate, n_mels=n_mels)(normed_sample)\n",
    "    \n",
    "    return mel.log2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# my_spectrogram = generate_spectrogram( noise_sample=my_recordings['t'][0] )\n",
    "# plt.figure(figsize=(2, 2))\n",
    "# plt.imshow(my_spectrogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net: preparing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a dictionary of labeled noise sample recordings, prepare the datasets and data loaders needed to train and test the model. Some of the model construction, training, and evaluation code here has been adapted from a [pytorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the noise data for handing to the convolutional neural network, for training and testing\n",
    "\n",
    "class NoisesDataset(Dataset):\n",
    "    \"\"\" Noises dataset. Takes a dictionary of recordings and returns spectrograms when data is requested. \n",
    "    A channel dimension is added to each spectrogram, as needed for the CNN. \"\"\"\n",
    "\n",
    "    def __init__(self, noise_data_dict, samplerate=samplerate, n_mels=N_MELS): \n",
    "        \"\"\" Initialization: \n",
    "        Takes a dictionary of noise samples, with labels as keys and lists of\n",
    "        flattened numpy arrays (one array per noise sample) as values. \n",
    "        Computes spectrograms for each. \"\"\"\n",
    "        \n",
    "        self.noise_data_dict = noise_data_dict\n",
    "        self.noise_samples = []\n",
    "        self.labels = []\n",
    "        \n",
    "        self.noise_str_to_int = {} # correspondences between integer and string labels\n",
    "        self.noise_int_to_str = {} \n",
    "        i = 0\n",
    "        \n",
    "        for label, list_of_arrays in noise_data_dict.items():\n",
    "            # extract samples and labels from the dictionary\n",
    "            num_samples = len(noise_data_dict[label])\n",
    "            self.noise_samples += noise_data_dict[label]\n",
    "            self.labels += [label] * num_samples\n",
    "            \n",
    "            # assign a unique integer to each string label\n",
    "            if label not in self.noise_str_to_int:\n",
    "                self.noise_str_to_int[label] = i\n",
    "                self.noise_int_to_str[i] = label\n",
    "                i += 1\n",
    "        \n",
    "        # compute spectrograms, and convert labels to integers\n",
    "        self.spectrograms = [ generate_spectrogram(s, samplerate, n_mels) \n",
    "                              for s in self.noise_samples ]\n",
    "        self.labels = [ self.noise_str_to_int[ L ] for L in self.labels ]\n",
    "\n",
    "    def __len__(self):\n",
    "        \" Return  the total number of samples \"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, sample_index):\n",
    "        \" Return one sample of data \"\n",
    "        # Load data and get (integer) label\n",
    "        # Note the CNN will expect the first tensor dimension to be the channel, hence the unsqueeze\n",
    "        X = self.spectrograms[sample_index].unsqueeze(0)\n",
    "        y = self.labels[sample_index]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "# adapted from https://stackoverflow.com/questions/53916594/typeerror-object-of-type-numpy-int64-has-no-len\n",
    "def prepare_data_loaders(full_dataset, training_fraction=0.8, batch_size=8):\n",
    "    \"\"\" Prepare data loaders for training and testing of the model. \"\"\"\n",
    "\n",
    "    # split into training and testing datasets\n",
    "    train_size = int(training_fraction * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "    # create data loaders\n",
    "    train_params = {\n",
    "        'batch_size': batch_size,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 1,\n",
    "    }\n",
    "    train_loader = DataLoader(dataset=train_dataset, **train_params)\n",
    "    test_loader  = DataLoader(dataset=test_dataset)\n",
    "    \n",
    "    return train_loader, test_loader, train_dataset, test_dataset\n",
    "\n",
    "def prepare_even_data_loaders(full_dataset, training_fraction=0.8, batch_size=8):\n",
    "    \"\"\" Prepare data loaders for training and testing of the model, including \n",
    "    training_fraction of each type in the training dataset. \"\"\"\n",
    "    \n",
    "    train_dataset = NoisesDataset({})\n",
    "    test_dataset  = NoisesDataset({})\n",
    "    \n",
    "    # iterate through noise labels, adding training_fraction of each\n",
    "    # to the training dataset/loader\n",
    "    unique_int_labels = list(set(full_dataset.labels))\n",
    "    dataset_element_labels = np.array([ d[1] for d in full_dataset ])\n",
    "    for i in unique_int_labels:\n",
    "        # get an array of indices, of noise samples with label i\n",
    "        i_indices = np.nonzero(dataset_element_labels == i)[0]\n",
    "        num_samples = len(i_indices)\n",
    "        train_size = int(training_fraction * num_samples)\n",
    "        test_size = num_samples - train_size\n",
    "\n",
    "        # make datasets for just that noise label\n",
    "        i_dataset = Subset(full_dataset, i_indices)\n",
    "        i_train_dataset, i_test_dataset = random_split(i_dataset, [train_size, test_size])\n",
    "\n",
    "        # add these datasets to the overall collections\n",
    "        train_dataset = ConcatDataset([train_dataset, i_train_dataset])\n",
    "        test_dataset  = ConcatDataset([test_dataset,  i_test_dataset])\n",
    "\n",
    "    # create the data loaders\n",
    "    train_params = {\n",
    "        'batch_size': batch_size,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 1,\n",
    "    }\n",
    "    train_loader = DataLoader(dataset=train_dataset, **train_params)\n",
    "    test_loader  = DataLoader(dataset=test_dataset)\n",
    "    \n",
    "    return train_loader, test_loader, train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # TESTING prepare_data_loaders\n",
    "# my_dataset = NoisesDataset(my_recordings)\n",
    "# my_train_loader, my_test_loader, my_train_dataset, my_test_dataset = prepare_data_loaders(my_dataset, batch_size=8)\n",
    "\n",
    "# # get some random training spectrograms\n",
    "# my_train_dataiter = iter(my_train_loader)\n",
    "# my_spectrograms, my_labels = my_train_dataiter.next()\n",
    "# my_batch_size = 8\n",
    "\n",
    "# # show spectrograms and print labels\n",
    "# fig, ax = plt.subplots(1, my_batch_size)\n",
    "# for i in range(len(my_spectrograms)):\n",
    "#     ax[i].imshow(my_spectrograms[i][0].numpy()) # the 0 selects the first (only) channel\n",
    "# print(' '.join('{:>4s}'.format(my_dataset.noise_int_to_str[my_labels[j].item()]) for j in range(my_batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING prepare_even_data_loaders\n",
    "# my_dataset = NoisesDataset(my_recordings)\n",
    "# my_train_loader, my_test_loader, my_train_dataset, my_test_dataset = prepare_even_data_loaders(my_dataset, batch_size=8)\n",
    "\n",
    "# # get some random training spectrograms\n",
    "# my_train_dataiter = iter(my_train_loader)\n",
    "# my_spectrograms, my_labels = my_train_dataiter.next()\n",
    "# my_batch_size = 8\n",
    "\n",
    "# # show spectrograms and print labels\n",
    "# fig, ax = plt.subplots(1, my_batch_size)\n",
    "# for i in range(len(my_spectrograms)):\n",
    "#     ax[i].imshow(my_spectrograms[i][0].numpy()) # the 0 selects the first (only) channel\n",
    "# print(' '.join('{:>4s}'.format(my_dataset.noise_int_to_str[my_labels[j].item()]) for j in range(my_batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net: defining and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the convolutional neural network, and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, image_size, noise_int_to_str):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # the spectrogram image size is needed to compute layer sizes\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        # the dictionary of noise labels is needed for translating predictions in the final layer\n",
    "        self.noise_int_to_str = noise_int_to_str\n",
    "        \n",
    "        \n",
    "        # image_size is a 2-tuple, the expected dimensions of each spectrogram\n",
    "        # .... or a 3-tuple, if the channel has already been added\n",
    "        if   len(image_size) == 2:\n",
    "            h, w = image_size\n",
    "        elif len(image_size) == 3:\n",
    "            channel, h, w = image_size\n",
    "        \n",
    "        # number of output nodes, (square) kernel size, and pool size per convolution layer,\n",
    "        # assuming the stride for pooling is the same as the pool size\n",
    "        kernels = [3, 3]\n",
    "        pool = 2\n",
    "        \n",
    "        # compute the number of input nodes for the first dense layer\n",
    "        h_out, w_out = h, w\n",
    "        for k in kernels:\n",
    "            # the convolution.\n",
    "            h_out += -k + 1\n",
    "            w_out += -k + 1\n",
    "            \n",
    "            # the pool. (from help(torch.nn.MaxPool2d))\n",
    "            h_out = int( (h_out - pool) / pool + 1 )\n",
    "            w_out = int( (w_out - pool) / pool + 1 )\n",
    "            \n",
    "        self.image_out = h_out * w_out\n",
    "        \n",
    "        # define the layers. The numbers of nodes chosen do not have deep thought behind them.\n",
    "        self.conv0 = nn.Conv2d(1, 32, kernels[0])\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv1 = nn.Conv2d(32, 10, kernels[1])\n",
    "        self.fc0 = nn.Linear(10 * self.image_out, 50)\n",
    "        self.fc1 = nn.Linear(50, 10)\n",
    "        # number of output nodes for final dense layer: the number of noise types        \n",
    "        self.fc2 = nn.Linear(10, len(noise_int_to_str))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv0(x)))\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 10 * self.image_out)\n",
    "        x = F.relu(self.fc0(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, epochs, train_loader, batch_progress=50):\n",
    "    \"\"\" Use training data from train_loader to train net for a number of epochs,\n",
    "    using a cross entropy loss function and Adam as the optimizer. \"\"\"\n",
    "    \n",
    "    # the loss function and optimizing method\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters())\n",
    "    \n",
    "    batch_num = 0\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        \n",
    "        batch_running_loss = 0.0\n",
    "        \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # accrue loss for printing\n",
    "            batch_running_loss += loss.item()\n",
    "            \n",
    "            # print progress every batch_progress batches\n",
    "            if batch_num % batch_progress == batch_progress-1:\n",
    "                print('[{:d}, {:5d}] loss: {:.3f}'.format(\n",
    "                  epoch + 1, i + 1, batch_running_loss / batch_progress))\n",
    "                batch_running_loss = 0.0\n",
    "                batch_num = 0\n",
    "            \n",
    "            batch_num += 1\n",
    "        \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# my_net = Net(my_spectrogram.size(), my_dataset.noise_int_to_str)\n",
    "# train_net(my_net, 50, my_train_loader, batch_progress=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the accuracy of the model against the testing and training sets, and compute the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_rating(net, dataloader, dataset_label):\n",
    "    \"\"\" Print the fraction of correct predictions on a data loader. \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_targets = torch.tensor([], dtype=torch.long)\n",
    "    all_predictions = torch.tensor([], dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            spectrograms, labels = data\n",
    "            outputs = net(spectrograms)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_predictions = torch.cat( \n",
    "                (all_predictions, predicted), dim=0 )\n",
    "            all_targets = torch.cat( \n",
    "                (all_targets, labels), dim=0 )\n",
    "            \n",
    "    print('Accuracy of the network on the {} {} spectrograms: {:.0f} %'.format(\n",
    "        total,\n",
    "        dataset_label,\n",
    "        100 * correct / total))\n",
    "    \n",
    "    return all_predictions, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://deeplizard.com/learn/video/0LhiS6yu2qQ\n",
    "def plot_confusion_matrix(predictions, targets, labels_int_to_str, \n",
    "                          normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\" Compute and display the confusion matrix. \"\"\"\n",
    "    \n",
    "    stacked = torch.stack( [targets, predictions], dim=1 )\n",
    "    all_int_labels = sorted(list(labels_int_to_str.keys()))\n",
    "    num_labels = len(all_int_labels)\n",
    "    confusion_matrix = torch.zeros(num_labels, num_labels, dtype=torch.int64)\n",
    "\n",
    "    for pair in stacked:\n",
    "        target_label, prediction_label = pair.tolist()\n",
    "        confusion_matrix[target_label, prediction_label] += 1\n",
    "\n",
    "    classes = [ labels_int_to_str[i] for i in all_int_labels ]    \n",
    "    cm = confusion_matrix # rename for compactness\n",
    "        \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        # print('Confusion matrix, without normalization:')\n",
    "        pass\n",
    "        \n",
    "    size = min(0.7 * (num_labels + 1), 8)\n",
    "    plt.figure(figsize=(size, size))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", \n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# accuracy_rating(my_net, my_train_loader, 'training')\n",
    "# preds, targets = accuracy_rating(my_net, my_test_loader, 'test')\n",
    "\n",
    "# plot_confusion_matrix(preds, targets, my_dataset.noise_int_to_str);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time listening and recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the trained model in hand, make a listener to recognize noises and act on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model, noise_sample, samplerate=samplerate, n_mels=N_MELS):\n",
    "    \"\"\" Build the spectrogram and use our model to recognize the noise \"\"\"\n",
    "    \n",
    "    mel = generate_spectrogram(noise_sample, samplerate, n_mels)\n",
    "\n",
    "    # change from torch.Size([A, B]) to torch.Size([1, 1, A, B])\n",
    "    mel = mel[None, None, :, :]\n",
    "    \n",
    "    # run through the model and get prediction\n",
    "    output = model(mel)\n",
    "    energy, label = torch.max(output.data, 1)\n",
    "    \n",
    "    # return the string label of the noise\n",
    "    return model.noise_int_to_str[label.item()]\n",
    "\n",
    "def print_noise(noise_heard):\n",
    "    \"\"\" Print the string label of the noise that has been heard. \"\"\"\n",
    "    print(noise_heard, end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_recognize_and_respond(model, act_on_noise, device=device, duration=5):\n",
    "    \"\"\" Continuously listen for noises for duration (sec), then recognize them\n",
    "    with the model and respond with the function act_on_noise. \"\"\"\n",
    "    \n",
    "    def processing_function(noise_sample):\n",
    "        pred = get_prediction(model, noise_sample)\n",
    "        act_on_noise(pred)\n",
    "    \n",
    "    listen_and_process(processing_function=processing_function, \n",
    "                           stop_condition=time_elapsed(duration),\n",
    "                           device=device,\n",
    "                           print_after_processing=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note this supposes that the default samplerate and n_mels for get_prediction are the same as those used for the training dataset. This could be made more robust by allowing processing_function to accept the sample rate as well as a numpy array, and by recording the n_mels used in the dataset the model was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# listen_recognize_and_respond(my_net, print_noise, device=2, duration=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving/loading recordings and models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to save (and load) recordings and models, if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions to save or load generic files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(data, filename, rewrite, basepath, extension, save_function): \n",
    "    \"\"\" Save data to basepath/filename.extension using save_function \"\"\"\n",
    "    \n",
    "    # Get a nonempty filename. Require it to be unique unless rewrite=True.\n",
    "    while True:\n",
    "        if filename is None:\n",
    "            print('Enter filename to write to (leave blank to cancel):')\n",
    "            filename = input()\n",
    "\n",
    "        if filename == '':\n",
    "            print(\"No filename provided. Aborting.\")\n",
    "            return\n",
    "\n",
    "        # Add the extension if it isn't already included\n",
    "        if filename[-4:] != extension:\n",
    "            filename += extension\n",
    "\n",
    "        # Make the base directory if it doesn't already exist\n",
    "        if not os.path.exists(basepath):\n",
    "            os.makedirs(basepath)\n",
    "\n",
    "        # Don't accidentally overwrite an existing file\n",
    "        valid_filename = True\n",
    "        if not rewrite:\n",
    "            with os.scandir(basepath) as entries:\n",
    "                for entry in entries:\n",
    "                    if entry.name == filename:\n",
    "                        print('File {} already exists. Use rewrite=True to overwrite.\\n'.format(\n",
    "                        './' + basepath + filename))\n",
    "                        filename = None\n",
    "                        valid_filename = False\n",
    "        \n",
    "        if valid_filename:\n",
    "            break\n",
    "\n",
    "    # Write the file, if we've made it this far\n",
    "    path = basepath + filename\n",
    "    save_function(data, path)\n",
    "    print('Data saved to', path)\n",
    "    \n",
    "    return path\n",
    "    \n",
    "def load_file(filename, basepath, load_function):\n",
    "    \"\"\" Load a file from basepath/filename \"\"\"\n",
    "    \n",
    "    # check if the base directory exists\n",
    "    if not os.path.exists(basepath):\n",
    "        print(\"Base directory {} doesn't exist. Aborting.\".format(basepath))\n",
    "        return \n",
    "\n",
    "    # Get the filename if one wasn't provided, abort if empty\n",
    "    if filename is None:\n",
    "        # display the available files for user convenience\n",
    "        print('Files in {} include:'.format(basepath))\n",
    "        with os.scandir(basepath) as entries:\n",
    "            for entry in entries:\n",
    "                print(entry.name)\n",
    "\n",
    "        print('\\nEnter filename to load:')\n",
    "        filename = input()\n",
    "        if filename == '':\n",
    "            print('Aborting.')\n",
    "            return\n",
    "        \n",
    "    # Abort if the file doesn't exist\n",
    "    with os.scandir(basepath) as entries:\n",
    "        if filename not in [ entry.name for entry in entries ]:\n",
    "            print('File does not exist. Aborting.')\n",
    "            return \n",
    "   \n",
    "    # Load the file, if we've made it this far.\n",
    "    path = basepath + filename\n",
    "    loaded_data = load_function(path)\n",
    "    print('File loaded:', path)\n",
    "\n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save or load noise sample dictionaries, with audio data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_BASEPATH = 'saved_noise_sample_dictionaries/'\n",
    "\n",
    "def save_noise_sample_dict(noise_data_dict, filename=None, rewrite=False, basepath=DICT_BASEPATH): \n",
    "    \"\"\" Save the dictionary of noise sample recordings \"\"\"\n",
    "    \n",
    "    def save_function(data, path):\n",
    "        np.save(path, data)\n",
    "        \n",
    "    return save_file(data=noise_data_dict, filename=filename, rewrite=rewrite,\n",
    "                    basepath=basepath, extension=\".npy\", save_function=save_function)\n",
    "    \n",
    "def load_noise_sample_dict(filename=None, basepath=DICT_BASEPATH):\n",
    "    \"\"\" Load a dictionary of noise sample recordings \"\"\"\n",
    "    \n",
    "    def load_function(path):\n",
    "        return np.load(path, allow_pickle=True).item()\n",
    "        \n",
    "    return load_file(filename=filename, basepath=basepath, load_function=load_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# save_noise_sample_dict(my_recordings)\n",
    "# my_loaded_file = load_noise_sample_dict(filename='my_recordings.npy')\n",
    "# my_loaded_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save or load trained models. This required saving (or loading) both the trained model parameters, as well as the image_size and noise_int_to_str dictionary needed to instantiate the model. These are done in tandem, so that loading a model automatically returns the fully restored model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_BASEPATH = 'trained_models/'\n",
    "\n",
    "def get_paired_filenames(filename):\n",
    "    # If a filename is given, return the two associated files with appropriate extensions.\n",
    "    if type(filename) is str:\n",
    "        if   len(filename) > 4 and filename[-4:] == \".pth\":\n",
    "            params_filename = filename\n",
    "            init_filename   = filename[:-4] + \".npy\"\n",
    "        elif len(filename) > 4 and filename[-4:] == \".npy\":\n",
    "            params_filename = filename[:-4] + \".pth\"\n",
    "            init_filename   = filename\n",
    "        else:\n",
    "            params_filename = filename + \".pth\"\n",
    "            init_filename   = filename + \".npy\"\n",
    "        return params_filename, init_filename\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def save_model(model, filename=None, rewrite=False, basepath=MODEL_BASEPATH): \n",
    "    \"\"\" Save the trained model parameters, and also the image_size and noise_int_to_str dictionary \"\"\"\n",
    "    \n",
    "    def save_function_parameters(data, path):\n",
    "        torch.save(data.state_dict(), path)\n",
    "        \n",
    "    def save_function_init(data, path):\n",
    "        np.save(path, (data.image_size, data.noise_int_to_str))\n",
    "    \n",
    "    # save the neural net parameters\n",
    "    print('Saving the model parameters (.pth) ...')\n",
    "    parameters_path = save_file(data=model, filename=filename, rewrite=rewrite,\n",
    "                                basepath=basepath, extension=\".pth\",\n",
    "                                save_function=save_function_parameters)\n",
    "    \n",
    "    # abort if that save failed\n",
    "    if parameters_path is None:\n",
    "        return\n",
    "    \n",
    "    # save the image_size and noise_int_to_str dictionary to the same directory\n",
    "    # and filename, different extension. These are needed to initialize a new Net\n",
    "    print('Saving the image_size and noise_int_to_str (.npy) ...')\n",
    "    filename = parameters_path[len(MODEL_BASEPATH):-4]\n",
    "    init_path = save_file(data=model, filename=filename, rewrite=rewrite,\n",
    "                                basepath=basepath, extension=\".npy\",\n",
    "                                save_function=save_function_init)\n",
    "        \n",
    "    return parameters_path, init_path\n",
    "    \n",
    "def load_model(filename=None, basepath=MODEL_BASEPATH):\n",
    "    \"\"\" Load and initialize trained model \"\"\"\n",
    "    \n",
    "    def load_function_params(path):\n",
    "        state_dict = torch.load(path)\n",
    "        return state_dict\n",
    "    \n",
    "    def load_function_init(path):\n",
    "        image_size, noise_int_to_str = np.load(path, allow_pickle=True)\n",
    "        return image_size, noise_int_to_str\n",
    "    \n",
    "    # If no filename is given, prompt for filenames. Otherwise, load the two associated files.\n",
    "    params_filename, init_filename = get_paired_filenames(filename)\n",
    "    if (params_filename, init_filename) == (None, None):\n",
    "        print('Load the parameters file, with extension .pth\\n')\n",
    "        state_dict = load_file(filename=None, basepath=basepath, load_function=load_function_params)\n",
    "        if state_dict is None:\n",
    "            return\n",
    "        print('\\nLoad the initialization file, with extension .npy\\n')\n",
    "        model_init = load_file(filename=None, basepath=basepath, load_function=load_function_init)\n",
    "    else:\n",
    "        print('Loading the parameters file (.pth) ...')\n",
    "        state_dict = load_file(filename=params_filename, basepath=basepath, load_function=load_function_params)\n",
    "        print('\\nLoading the initialization file (.npy) ...')\n",
    "        model_init = load_file(filename=init_filename,   basepath=basepath, load_function=load_function_init)\n",
    "    \n",
    "    # Abort if either load failed.\n",
    "    if (state_dict is None) or (model_init is None):\n",
    "        print('Could not load both files. Aborting.')\n",
    "        return\n",
    "    \n",
    "    # Build the model from the resulting data\n",
    "    image_size, noise_int_to_str = model_init\n",
    "    model = Net(image_size, noise_int_to_str)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# save_model(my_net, filename='my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# new_model = load_model(filename='my_model')\n",
    "# print(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From recording to recognizing: all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define two functions:\n",
    "* `build_beatbot` to record training audio + train the model + evaluate the model, and\n",
    "* `run_beatbot` to continuously listen + recognize noises + act on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_beatbot(device=device, starting_noise_data={},\n",
    "                  skip_recording=False,\n",
    "                  batch_size=8, epochs=10, batch_progress=100,\n",
    "                  skip_testing_model=False,\n",
    "                  save_recordings_filename=None, rewrite_recordings_file=False,\n",
    "                  save_model_filename=None,      rewrite_model_file=False):\n",
    "    \"\"\" Record audio data, train a model, evaluate it, and optionally save the results.\n",
    "    If skip_testing_model is True, use all data for training and skip the model testing.\"\"\"\n",
    "    \n",
    "    # Record training data and construct the dataset\n",
    "    if skip_recording:\n",
    "        noise_data_dict = starting_noise_data\n",
    "    else:\n",
    "        noise_data_dict = record_model_data(device=device, starting_noise_data=starting_noise_data)\n",
    "        \n",
    "    dataset = NoisesDataset(noise_data_dict)\n",
    "    \n",
    "    # Prepare the dataloader. Use all data as training data if skip_testing_model is True.\n",
    "    if skip_testing_model:\n",
    "        training_fraction = 1\n",
    "    else:\n",
    "        training_fraction = 0.8\n",
    "    train_loader, test_loader, _, _ = prepare_even_data_loaders(dataset, batch_size=batch_size,\n",
    "                                                                training_fraction=training_fraction)\n",
    "    \n",
    "    # Build and train the neural net\n",
    "    image_size = dataset[0][0].size()\n",
    "    model = Net(image_size, dataset.noise_int_to_str)\n",
    "    train_net(model, epochs, train_loader, batch_progress=batch_progress)\n",
    "    \n",
    "    # Evaluate the model and show the confusion matrix, or skip testing altogether.\n",
    "    if not skip_testing_model:\n",
    "        preds, targets = accuracy_rating(model, test_loader, 'test')\n",
    "        plot_confusion_matrix(preds, targets, dataset.noise_int_to_str);\n",
    "    \n",
    "    # Offer to save the recordings and model\n",
    "    print('\\nWould you like to save your audio data?')\n",
    "    save_noise_sample_dict( noise_data_dict, filename=save_recordings_filename, rewrite=rewrite_recordings_file )\n",
    "    print('\\nWould you like to save your model?')\n",
    "    save_model( model, filename=save_model_filename, rewrite=rewrite_model_file )\n",
    "    \n",
    "    return model, noise_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# my_model, my_recordings = build_beatbot(device=2, starting_noise_data=my_recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently `run_beatbot` is just an alias to `listen_recognize_and_respond`, from earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_beatbot = listen_recognize_and_respond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# listen_recognize_and_respond(my_model, print_noise, device=0, duration=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
